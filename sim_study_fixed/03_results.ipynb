{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---------\n",
        "title: Simulation study results\n",
        "jupyter: python3\n",
        "---------\n"
      ],
      "id": "1b0b6149"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from config import *\n",
        "import json\n",
        "import pandas as pd\n",
        "import plotnine as pn"
      ],
      "id": "8cff524a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "list_posteriors = []\n",
        "posteriors_sims = []\n",
        "failed_sims = []\n",
        "for i in range(NUM_SIMS):\n",
        "    try:\n",
        "        f = os.path.join(RESULTS_DIR, f\"posterior_{i}.npy\")\n",
        "        list_posteriors.append(np.load(f, allow_pickle=True))\n",
        "    except Exception as e:\n",
        "        print(f\"Failed loading {i}: {e}\")\n",
        "        failed_sims.append(i)\n",
        "    else:\n",
        "        posteriors_sims.append(i)\n",
        "posteriors = np.stack(list_posteriors)\n",
        "del list_posteriors\n",
        "\n",
        "with open(os.path.join(RESULTS_DIR, \"sim_params.json\"), \"r\") as fp:\n",
        "    true_params = json.load(fp)\n",
        "log_posterior = PROBABILISTIC_MODEL_CLASS(model, None, None, PRIORS)"
      ],
      "id": "39b6939c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "thinned_params = range(300_000, posteriors.shape[1], 100)\n",
        "num_sims = posteriors.shape[0]\n",
        "num_iters = posteriors.shape[1]\n",
        "# df = pd.DataFrame(\n",
        "#     posteriors[:,thinned_params,:].flatten(),\n",
        "#     index=pd.MultiIndex.from_product([range(num_sims), thinned_params, log_posterior.get_param_names()],\n",
        "#                                      names=[\"sim\", \"iteration\", \"param\"]),\n",
        "#     columns=[\"value\"]\n",
        "# ).reset_index()\n",
        "df = pd.DataFrame(\n",
        "    posteriors[:,thinned_params,:].flatten(),\n",
        "    index=pd.MultiIndex.from_product([posteriors_sims, thinned_params, log_posterior.get_param_names()],\n",
        "                                     names=[\"sim\", \"iteration\", \"param\"]),\n",
        "    columns=[\"value\"]\n",
        ").reset_index()\n",
        "#del posteriors\n",
        "\n",
        "true_vals = []\n",
        "for s in posteriors_sims:\n",
        "    true_vals.extend(log_posterior.param_value_dict_to_array(true_params[s]))\n",
        "df_params = pd.DataFrame(\n",
        "    true_vals,\n",
        "    index=pd.MultiIndex.from_product([posteriors_sims, log_posterior.get_param_names()], names=[\"sim\", \"param\"]),\n",
        "    columns=[\"true\"]\n",
        ").reset_index()"
      ],
      "id": "617946dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# From: https://gist.github.com/paulgb/6627336\n",
        "def binom_interval(success, total, confint=0.95):\n",
        "    quantile = (1 - confint) / 2.\n",
        "    lower = stats.beta.ppf(quantile, success, total - success + 1)\n",
        "    lower[success == 0] = 0\n",
        "    upper = stats.beta.ppf(1 - quantile, success + 1, total - success)\n",
        "    upper[success == total] = 1\n",
        "    return (lower, upper)\n",
        "\n",
        "\"\"\"Calculate the coverage of credible intervals.\n",
        "\n",
        "Params:\n",
        "    truth: dataframe with true values in a column labelled 'true' which is merged with the posterior\n",
        "    posterior: array of posterior values\n",
        "    remaining_axis_names: names of the axis of the posterior after `axis_to_remove` is removed. Should include the column containing the simulation number.\n",
        "    remaining_axis_labels: labels for each cell of the axis in `remaining_axis_names`\n",
        "    groups: list of column(s) the return values should be grouped by (eg: date and/or age)\n",
        "    axis_to_remove: number of the axis of the posterior array which will have quantiles taken over (normally contains the samples)\n",
        "    intervals: width of credible intervals to consider\n",
        "    \n",
        "Returns:\n",
        "    dataframe with the following columns:\n",
        "        those listed in `groups`\n",
        "        interval: the size of the credible interval the row refers to\n",
        "        sum: the number of credible intervals which contains the true value\n",
        "        size: the number of credible intervals\n",
        "        prop: the proportion of credible intervals which contain the true value\n",
        "        ul, ll: 95% Binomail confidence interval limits for `prop` based on sample size `size`\n",
        "        within: if the nominal coverage is within the confidence intervals\n",
        "\"\"\"\n",
        "def calc_coverage(truth, posterior, remaining_axis_names, remaining_axis_labels, groups, axis_to_remove=1, intervals = np.array([50, 75, 95])):\n",
        "    lower_limits = (1 - intervals/100) / 2\n",
        "    lls = []\n",
        "    uls = []\n",
        "    for limit in lower_limits:\n",
        "        lls.append(np.quantile(posterior, limit, axis=axis_to_remove))\n",
        "        uls.append(np.quantile(posterior, 1-limit, axis=axis_to_remove))\n",
        "    df_intervals = pd.DataFrame(\n",
        "        {\"ll\": np.stack(lls).flatten(), \"ul\": np.stack(uls).flatten()},\n",
        "        index=pd.MultiIndex.from_product(\n",
        "            [intervals] + remaining_axis_labels,\n",
        "            names=[\"interval\"] + remaining_axis_names\n",
        "        )\n",
        "    ).reset_index().merge(truth)\n",
        "    df_intervals[\"covered\"] = np.logical_and(df_intervals[\"ll\"] < df_intervals[\"true\"], df_intervals[\"true\"] < df_intervals[\"ul\"])\n",
        "    coverage = df_intervals.groupby(groups + [\"interval\"])[\"covered\"].agg([\"sum\", \"size\"]).reset_index()\n",
        "    coverage[\"prop\"] = coverage[\"sum\"] / coverage[\"size\"]\n",
        "    coverage[\"ll\"], coverage[\"ul\"] = binom_interval(coverage[\"sum\"], coverage[\"size\"])\n",
        "    coverage[\"within\"] = np.logical_and(coverage[\"interval\"]/100 > coverage[\"ll\"], coverage[\"interval\"]/100 < coverage[\"ul\"])\n",
        "    return coverage"
      ],
      "id": "aad69dce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "thinned_posterior = posteriors[:,thinned_params,:]\n",
        "coverage_param = calc_coverage(df_params, thinned_posterior, [\"sim\", \"param\"], [posteriors_sims, log_posterior.get_param_names()], [\"param\"])\n",
        "\n",
        "(pn.ggplot(coverage_param, pn.aes(colour=\"within\")) +\n",
        " pn.geom_point(pn.aes(y=\"param\", x=\"prop\", xmin=\"ll\", xmax=\"ul\")) +\n",
        " pn.geom_errorbarh(pn.aes(y=\"param\", xmin=\"ll\", xmax=\"ul\"), height = 0.001) +\n",
        " pn.facet_wrap(\"~interval\") +\n",
        " pn.geom_vline(pn.aes(xintercept=\"interval/100\"))\n",
        ")"
      ],
      "id": "a380147b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "    pn.ggplot(df[df[\"sim\"] < 5]) +\n",
        "    pn.geom_line(pn.aes(\"iteration\", \"value\")) +\n",
        "    pn.facet_grid(\"param~sim\", scales=\"free_y\") +\n",
        "    pn.theme(figure_size=(7, 13))\n",
        ")"
      ],
      "id": "455cf3f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_summary = pd.DataFrame(\n",
        "    {\"posterior_mean\": thinned_posterior.mean(axis=1).flatten()},\n",
        "    index=pd.MultiIndex.from_product([posteriors_sims, log_posterior.get_param_names()], names=[\"sim\", \"param\"])\n",
        ")\\\n",
        "    .reset_index()\\\n",
        "    .merge(df_params)\n",
        "df_summary[\"bias\"] = df_summary[\"posterior_mean\"] - df_summary[\"true\"]\n",
        "df_summary.groupby(\"param\")\\\n",
        "    .apply(lambda df: pd.DataFrame([[(df[\"bias\"].values**2).sum(), (df[\"bias\"].values / df[\"true\"].values).mean()]], columns=[\"MSE\", \"Relative bias\"]))"
      ],
      "id": "03b397fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dfs_ess = []\n",
        "for i in posteriors_sims:\n",
        "    df_ = pd.read_csv(os.path.join(RESULTS_DIR, f\"ESS_{i}.npy\"), names=[\"param\", \"ess\"])\n",
        "    df_[\"sim\"] = i\n",
        "    dfs_ess.append(df_)\n",
        "df_ess = pd.concat(dfs_ess)\n",
        "del dfs_ess"
      ],
      "id": "64916261",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_ess.groupby(\"param\")\\\n",
        "    .aggregate({\n",
        "        \"ess\": [\"mean\", \"min\", \"max\"]\n",
        "    })"
      ],
      "id": "ebe1e9ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_ess[(df_ess[\"ess\"] < 100) & (df_ess[\"param\"] != \"beta[0]\")]\\\n",
        "    .groupby(\"sim\").count()"
      ],
      "id": "6fadd677",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So sim 8 is bad but rest should be OK.\n"
      ],
      "id": "79dd7d80"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_ess[df_ess[\"sim\"] != 8].groupby(\"param\")\\\n",
        "    .aggregate({\n",
        "        \"ess\": [\"mean\", \"median\", \"min\", \"max\"]\n",
        "    })"
      ],
      "id": "48091740",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seems so.\n",
        "\n",
        "# Incidence and prevalence\n"
      ],
      "id": "5f69c31f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "true_results = read_csv(\n",
        "    os.path.join(RESULTS_DIR, \"sim_output.csv\"),\n",
        "    dtype={\n",
        "        \"age\": \"string\"\n",
        "    },\n",
        "    parse_dates=[2],\n",
        "    index_col=0\n",
        ")\n",
        "true_results[\"day\"] = (true_results[\"date\"] - pd.to_datetime(START_DATE)).dt.days"
      ],
      "id": "44641bb0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "thinned_for_predictive = range(0, thinned_posterior.shape[1], 4)\n",
        "predicted_incidence = np.empty((num_sims, len(thinned_for_predictive), N_DAYS, N_STRATA))\n",
        "predicted_prevalence = np.empty_like(predicted_incidence)\n",
        "for i, sim in enumerate(thinned_posterior):\n",
        "    for j, iter_num in enumerate(thinned_for_predictive):\n",
        "        result = log_posterior.simulate(sim[iter_num])[0]\n",
        "        predicted_incidence[i, j] = result[0]\n",
        "        predicted_prevalence[i, j] = result[1]"
      ],
      "id": "03476dd9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "incidence_coverage = calc_coverage(\n",
        "    truth=true_results.rename(columns={\"incidence\": \"true\"}),\n",
        "    posterior=predicted_incidence,\n",
        "    remaining_axis_names=[\"sim\", \"day\", \"age\"],\n",
        "    remaining_axis_labels=[posteriors_sims, range(N_DAYS), STRATA_NAMES],\n",
        "    groups=[\"day\", \"age\"]\n",
        ")\n",
        "prevalence_coverage = calc_coverage(\n",
        "    truth=true_results.rename(columns={\"prevalence\": \"true\"}),\n",
        "    posterior=predicted_prevalence,\n",
        "    remaining_axis_names=[\"sim\", \"day\", \"age\"],\n",
        "    remaining_axis_labels=[posteriors_sims, range(N_DAYS), STRATA_NAMES],\n",
        "    groups=[\"day\", \"age\"]\n",
        ")"
      ],
      "id": "3b716b8e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "    pn.ggplot(incidence_coverage) +\n",
        "    pn.geom_line(pn.aes(\"day\", \"prop\", colour=\"factor(interval)\")) +\n",
        "    pn.geom_ribbon(pn.aes(\"day\", ymin=\"ll\", ymax=\"ul\", fill=\"factor(interval)\"), alpha = 0.5) +\n",
        "    pn.facet_wrap(\"~age\") +\n",
        "    pn.geom_hline(pn.aes(yintercept=\"interval/100\"))\n",
        ")"
      ],
      "id": "4f2d513f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "    pn.ggplot(prevalence_coverage) +\n",
        "    pn.geom_line(pn.aes(\"day\", \"prop\", colour=\"factor(interval)\")) +\n",
        "    pn.geom_ribbon(pn.aes(\"day\", ymin=\"ll\", ymax=\"ul\", fill=\"factor(interval)\"), alpha = 0.5) +\n",
        "    pn.facet_wrap(\"~age\") +\n",
        "    pn.geom_hline(pn.aes(yintercept=\"interval/100\"))\n",
        ")"
      ],
      "id": "02e6bd61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for bias in this\n"
      ],
      "id": "e46a34c9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "posterior_predictive = pd.DataFrame(\n",
        "    {\n",
        "        \"incidence\": predicted_incidence.flatten(),\n",
        "        \"prevalence\": predicted_prevalence.flatten(),\n",
        "    },\n",
        "    index=pd.MultiIndex.from_product(\n",
        "        [posteriors_sims, thinned_for_predictive, range(N_DAYS), STRATA_NAMES],\n",
        "        names=[\"sim\", \"iteration\", \"day\", \"age\"]\n",
        "    )\n",
        ")\n",
        "compare_predictives = posterior_predictive\\\n",
        "    .groupby([\"sim\", \"day\", \"age\"])\\\n",
        "    .agg({\n",
        "        \"incidence\": \"mean\",\n",
        "        \"prevalence\": \"mean\",\n",
        "    })\\\n",
        "    .reset_index()\\\n",
        "    .merge(\n",
        "        true_results,\n",
        "        on=[\"sim\", \"day\", \"age\"],\n",
        "        suffixes=(\"_mean\", \"_true\")\n",
        "    )\n",
        "compare_predictives[\"incidence_rel_error\"] = (\n",
        "    (compare_predictives[\"incidence_mean\"] - compare_predictives[\"incidence_true\"])\n",
        "        / compare_predictives[\"incidence_mean\"]\n",
        ")\n",
        "compare_predictives[\"prevalence_rel_error\"] = (\n",
        "    (compare_predictives[\"prevalence_mean\"] - compare_predictives[\"prevalence_true\"])\n",
        "        / compare_predictives[\"prevalence_mean\"]\n",
        ")\n",
        "compare_predictives = compare_predictives\\\n",
        "    .groupby([\"day\", \"age\"])\\\n",
        "    .agg({\n",
        "        \"incidence_rel_error\": \"mean\",\n",
        "        \"prevalence_rel_error\": \"mean\",\n",
        "    })\\\n",
        "    .reset_index()"
      ],
      "id": "cb2ef6bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "    pn.ggplot(compare_predictives) +\n",
        "    pn.geom_line(pn.aes(\"day\", \"prevalence_rel_error\")) +\n",
        "    pn.facet_wrap(\"~age\")\n",
        ")"
      ],
      "id": "af62aebb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "    pn.ggplot(compare_predictives) +\n",
        "    pn.geom_line(pn.aes(\"day\", \"incidence_rel_error\")) +\n",
        "    pn.facet_wrap(\"~age\")\n",
        ")"
      ],
      "id": "c1871571",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "posterior_summary = posterior_predictive\\\n",
        "    .reset_index()\\\n",
        "    .groupby([\"sim\", \"day\", \"age\"])\\\n",
        "    .aggregate({\n",
        "        \"incidence\": \"mean\",\n",
        "        \"prevalence\": \"mean\",\n",
        "    })\\\n",
        "    .reset_index()\n",
        "(\n",
        "    pn.ggplot(\n",
        "        posterior_summary,\n",
        "        pn.aes(\"day\", \"incidence\", group=\"sim\")\n",
        "    ) +\n",
        "    pn.geom_line(alpha=0.1) +\n",
        "    pn.facet_wrap(\"~age\")\n",
        ")"
      ],
      "id": "58ca979e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate the beta[0] parameters\n"
      ],
      "id": "d3116a87"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sigma_summaries = df[df[\"param\"] == \"beta[0]\"]\\\n",
        "    .groupby(\"sim\")\\\n",
        "    .aggregate({\n",
        "        \"value\": [\"mean\", \"median\"]\n",
        "    })\\\n",
        "    .droplevel(0, axis=1)\\\n",
        "    .merge(\n",
        "        df_params[df_params[\"param\"] == \"beta[0]\"],\n",
        "        on=\"sim\"\n",
        "    )\n",
        "(\n",
        "    pn.ggplot(\n",
        "        sigma_summaries,\n",
        "        pn.aes(\"true\", \"mean\")\n",
        "     ) +\n",
        "    pn.geom_point() +\n",
        "    pn.geom_smooth(method=\"lm\", formula=\"y~x\")\n",
        ")"
      ],
      "id": "fd1d34f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Non-centered vs centered beta parameters\n",
        "\n",
        "Up until now, we have been looking at the non-centered beta parameters.\n",
        "However, we actually care about the centered ones.\n"
      ],
      "id": "4d599320"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sd_index = 0\n",
        "for param_name, param in log_posterior._model_params.items():\n",
        "    if param_name == \"beta\":\n",
        "        break\n",
        "    sd_index += len(param)\n",
        "\n",
        "ncp_beta_sds = posteriors[:,:,sd_index, np.newaxis]\n",
        "assert np.abs(np.mean(ncp_beta_sds) / 50) < 0.01\n",
        "ncp_betas = posteriors[:,:,sd_index+1:sd_index+1+model.num_betas]\n",
        "assert ncp_betas.shape[2] == model.num_betas\n",
        "centred_betas = ncp_betas * ncp_beta_sds"
      ],
      "id": "bad229ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "true_centred_betas = np.empty((len(posteriors_sims), model.num_betas))\n",
        "for i, s  in enumerate(posteriors_sims):\n",
        "    true_centred_betas[i] = true_params[s][\"beta\"][0] * np.array(true_params[s][\"beta\"][1:])\n",
        "assert true_centred_betas.shape == (centred_betas.shape[0], centred_betas.shape[2])"
      ],
      "id": "07868348",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_centred_betas_truth = pd.DataFrame(\n",
        "    {\"true\": true_centred_betas.flatten()},\n",
        "    index=pd.MultiIndex.from_product(\n",
        "        [posteriors_sims, np.arange(model.num_betas) + 1],\n",
        "        names=[\"sim\", \"index\"]\n",
        "    )\n",
        ").reset_index()"
      ],
      "id": "d40e8013",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "centered_beta_coverage = calc_coverage(\n",
        "    truth=df_centred_betas_truth,\n",
        "    posterior=centred_betas,\n",
        "    remaining_axis_names=[\"sim\", \"index\"],\n",
        "    remaining_axis_labels=[posteriors_sims, np.arange(model.num_betas) + 1],\n",
        "    groups=[\"index\"]\n",
        ")"
      ],
      "id": "40f2e9c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "    pn.ggplot(centered_beta_coverage, pn.aes(colour=\"within\")) +\n",
        "    pn.geom_point(pn.aes(y=\"index\", x=\"prop\", xmin=\"ll\", xmax=\"ul\")) +\n",
        "    pn.geom_errorbarh(pn.aes(y=\"param\", xmin=\"ll\", xmax=\"ul\"), height = 0.001) +\n",
        "    pn.facet_wrap(\"~interval\") +\n",
        "    pn.geom_vline(pn.aes(xintercept=\"interval/100\"))\n",
        ")"
      ],
      "id": "fa84575c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}